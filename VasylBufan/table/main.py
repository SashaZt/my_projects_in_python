import json
import random
import sys
import xml.etree.ElementTree as ET
from pathlib import Path
from urllib.parse import urlparse

import gspread
import numpy as np
import pandas as pd
import requests
from google.oauth2.service_account import Credentials
from loguru import logger
from lxml import etree

current_directory = Path.cwd()
xml_directory = current_directory / "xml"
log_directory = current_directory / "log"
config_directory = current_directory / "config"

config_directory.mkdir(parents=True, exist_ok=True)
log_directory.mkdir(parents=True, exist_ok=True)
xml_directory.mkdir(parents=True, exist_ok=True)
log_file_path = log_directory / "log_message.log"
config_file_path = config_directory / "config.json"
service_account_file = config_directory / "credentials.json"

logger.remove()
# üîπ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª
logger.add(
    log_file_path,
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {line} | {message}",
    level="DEBUG",
    encoding="utf-8",
    rotation="10 MB",
    retention="7 days",
)

# üîπ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å (—Ü–≤–µ—Ç–Ω–æ–π –≤—ã–≤–æ–¥)
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{line}</cyan> | <cyan>{message}</cyan>",
    level="DEBUG",
    enqueue=True,
)


def load_json_data(file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {file_path}: {e}")
        return None


def save_json_data(data, file_path):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ JSON —Ñ–∞–π–ª"""
    try:
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª {file_path}: {e}")
        return False


config = load_json_data(config_file_path)
URLS = config.get("competitor_www", [])
MY_URL = config.get("my_www")
HEADERS = config.get("headers", {})
SPREADSHEET = config["google"]["spreadsheet"]
SHEET = config["google"]["sheet"]


def get_google_sheet(sheet_one):
    """–ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ Google Sheets –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—ã–π –ª–∏—Å—Ç."""
    try:
        # –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–± –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å google-auth
        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive",
        ]

        credentials = Credentials.from_service_account_file(
            service_account_file, scopes=scopes
        )

        # –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ gspread —Å –Ω–æ–≤—ã–º–∏ —É—á–µ—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        client = gspread.authorize(credentials)

        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–æ –∫–ª—é—á—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª–∏—Å—Ç
        spreadsheet = client.open_by_key(SPREADSHEET)
        logger.info("–£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Google Spreadsheet.")
        return spreadsheet.worksheet(sheet_one)
    except FileNotFoundError:
        logger.error("–§–∞–π–ª —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å.")
        raise FileNotFoundError("–§–∞–π–ª —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å.")
    except gspread.exceptions.APIError as e:
        logger.error(f"–û—à–∏–±–∫–∞ API Google Sheets: {e}")
        raise
    except Exception as e:
        logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        raise


def update_sheet_with_data(sheet, data, total_rows=50000):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ª–∏—Å—Ç–∞ Google Sheets —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è."""
    if not data:
        raise ValueError("–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∏–∑ –∫–ª—é—á–µ–π —Å–ª–æ–≤–∞—Ä—è
    headers = list(data[0].keys())

    # –ó–∞–ø–∏—Å—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
    sheet.update(values=[headers], range_name="A1", value_input_option="RAW")

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏
    rows = [[entry.get(header, "") for header in headers] for entry in data]

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –¥–æ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ total_rows
    if len(rows) < total_rows:
        empty_row = [""] * len(headers)
        rows.extend([empty_row] * (total_rows - len(rows)))

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã—Ö
    end_col = chr(65 + len(headers) - 1)  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –≤ –±—É–∫–≤—É (A, B, C...)
    range_name = f"A2:{end_col}{total_rows + 1}"

    # –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤ –ª–∏—Å—Ç
    sheet.update(values=rows, range_name=range_name, value_input_option="USER_ENTERED")
    logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ {len(data)} —Å—Ç—Ä–æ–∫ –≤ Google Sheets")


def download_xml(url, headers):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç XML —Ñ–∞–π–ª –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É URL.

    Args:
        url (str): URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è XML —Ñ–∞–π–ª–∞
        headers (dict): –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è HTTP –∑–∞–ø—Ä–æ—Å–∞
        xml_dir (Path, optional): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é xml_directory.

    Returns:
        Path or None: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    try:
        if (
            url
            == "https://hdsport.com.ua/index.php?route=extension/feed/unixml/allprice"
        ):
            xml_file_path = xml_directory / "all.xml"
        else:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏–∑ URL
            filename = urlparse(url).path.split("/")[-1]

            # –ï—Å–ª–∏ –∏–º—è —Ñ–∞–π–ª–∞ –ø—É—Å—Ç–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ–º–µ–Ω
            if not filename:
                filename = urlparse(url).netloc.replace(".", "_")

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .xml –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if not filename.endswith(".xml"):
                xml_file_path = xml_directory / f"{filename}.xml"
            else:
                xml_file_path = xml_directory / filename

        logger.info(f"–°–∫–∞—á–∏–≤–∞–µ–º XML —Ñ–∞–π–ª: {url}")

        response = requests.get(
            url,
            headers=headers,
            timeout=100,
        )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞
        if response.status_code == 200:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ —Ñ–∞–π–ª
            with open(xml_file_path, "wb") as file:
                file.write(response.content)
            logger.info(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {xml_file_path}")
            return xml_file_path
        else:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {response.status_code}")
            return None
    except Exception as e:
        logger.error(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ {url}: {e}")
        return None


def download_all_xml_files():
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ XML —Ñ–∞–π–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.

    Args:
        config_file_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {url: –ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É_–∏–ª–∏_None}
    """
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

    results = {}

    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    for url in URLS:
        results[url] = download_xml(url, HEADERS)

    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if MY_URL:
        results[MY_URL] = download_xml(MY_URL, HEADERS)

    return results


def parse_sitemap_urls():
    """
    –ü–∞—Ä—Å–∏—Ç XML sitemap –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ URL –∏–∑ —Ç–µ–≥–æ–≤ <url><loc>

    Args:
        file_path (str): –ø—É—Ç—å –∫ XML —Ñ–∞–π–ª—É

    Returns:
        list: —Å–ø–∏—Å–æ–∫ URL-–æ–≤
    """
    urls = []
    for xml_file in xml_directory.glob("*.xml"):
        try:
            # –ü–∞—Ä—Å–∏–º XML —Ñ–∞–π–ª
            tree = ET.parse(xml_file)
            root = tree.getroot()

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–º–µ–Ω (namespace), –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
            namespace = {"sitemap": "http://www.sitemaps.org/schemas/sitemap/0.9"}

            # –ò—â–µ–º –≤—Å–µ —Ç–µ–≥–∏ <url> –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º <loc>
            for url in root.findall(".//sitemap:url", namespace):
                loc = url.find("sitemap:loc", namespace)

                if loc is not None and loc.text:
                    urls.append(loc.text)

            # return urls

        except ET.ParseError as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")
            return []
        except FileNotFoundError:
            print(f"–§–∞–π–ª {xml_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(urls)} URL-–æ–≤")


def parsin_xml():
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ sku
    data_dict = {}
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ ean –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    ean_dict = {}
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è SKU –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ INS
    normalized_sku_dict = {}

    # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
    matched_data = []  # –î–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã
    unmatched_data = []  # –î–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω—ã

    # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª "all", —á—Ç–æ–±—ã —Å–æ–±—Ä–∞—Ç—å sku –∏ ean
    for xml_file in xml_directory.glob("*.xml"):
        name_file = xml_file.stem

        if name_file == "all":
            tree = etree.parse(xml_file)
            root = tree.getroot()
            offers = root.xpath("//offer")

            for offer in offers:
                price_my_site = extract_xml_value(offer, "price")
                sku = (
                    offer.xpath('param[@name="sku"]/text()')[0]
                    if offer.xpath('param[@name="sku"]')
                    else None
                )

                ean = (
                    offer.xpath('param[@name="ean"]/text()')[0]
                    if offer.xpath('param[@name="ean"]')
                    else None
                )

                if sku:  # –ò—Å–ø–æ–ª—å–∑—É–µ–º sku –∫–∞–∫ –∫–ª—é—á
                    data_dict[sku] = {
                        "–ú–æ–π —Å–∞–π—Ç sku": sku,
                        "–ú–æ–π —Å–∞–π—Ç ean": ean,
                        "–ú–æ–π —Å–∞–π—Ç —Ü–µ–Ω–∞": price_my_site,
                        "insportline vendor_code": None,
                        "insportline —Ü–µ–Ω–∞": None,
                        "xcore_sku": None,
                        "xcore_price": None,
                        "matched": False,  # –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
                    }

                    # –ï—Å–ª–∏ –µ—Å—Ç—å EAN, —Å–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∑–∞–ø–∏—Å—å –≤ data_dict
                    if ean:
                        ean_dict[ean] = sku

                    # –°–æ–∑–¥–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é SKU (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ INS)
                    normalized_sku = normalize_sku(sku)
                    normalized_sku_dict[normalized_sku] = sku

    # –¢–µ–ø–µ—Ä—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è insportline (vendorCode)
    for xml_file in xml_directory.glob("*.xml"):
        name_file = xml_file.stem

        if name_file in ["export_yandex_market", "yml_dualprice"]:
            tree = etree.parse(xml_file)
            root = tree.getroot()
            offers = root.xpath("//offer")

            for offer in offers:
                vendor_code = extract_xml_value(offer, "vendorCode")
                insportline_price = extract_xml_value(offer, "price")

                if not vendor_code:
                    continue

                match_found = False

                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å –ø–æ sku
                if vendor_code in data_dict:
                    # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é SKU
                    data_dict[vendor_code]["insportline vendor_code"] = vendor_code
                    data_dict[vendor_code]["insportline —Ü–µ–Ω–∞"] = insportline_price
                    data_dict[vendor_code]["matched"] = True
                    match_found = True
                else:
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º vendor_code –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    normalized_vendor = normalize_sku(vendor_code)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É SKU
                    if normalized_vendor in normalized_sku_dict:
                        original_sku = normalized_sku_dict[normalized_vendor]
                        data_dict[original_sku]["insportline vendor_code"] = vendor_code
                        data_dict[original_sku]["insportline —Ü–µ–Ω–∞"] = insportline_price
                        data_dict[original_sku]["matched"] = True
                        match_found = True
                    else:
                        # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ EAN
                        ean_value = extract_xml_value(
                            offer, "barcode"
                        ) or extract_xml_value(offer, "ean")

                        if ean_value and ean_value in ean_dict:
                            # –ù–∞—à–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ EAN
                            matching_sku = ean_dict[ean_value]
                            data_dict[matching_sku][
                                "insportline vendor_code"
                            ] = vendor_code
                            data_dict[matching_sku][
                                "insportline —Ü–µ–Ω–∞"
                            ] = insportline_price
                            data_dict[matching_sku]["matched"] = True
                            match_found = True

                if not match_found:
                    # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–∏ –ø–æ SKU, –Ω–∏ –ø–æ EAN, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                    new_key = f"insportline_{vendor_code}"
                    data_dict[new_key] = {
                        "–ú–æ–π —Å–∞–π—Ç sku": None,
                        "–ú–æ–π —Å–∞–π—Ç ean": None,
                        "–ú–æ–π —Å–∞–π—Ç —Ü–µ–Ω–∞": None,
                        "insportline vendor_code": vendor_code,
                        "insportline —Ü–µ–Ω–∞": insportline_price,
                        "xcore_sku": None,
                        "xcore_price": None,
                        "matched": False,  # –≠—Ç–æ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å
                    }

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ JSON —Ñ–∞–π–ª–∞ xcore_com_ua.json
    try:
        with open("data/xcore_com_ua.json", "r", encoding="utf-8") as f:
            xcore_data = json.load(f)

        for item in xcore_data:
            xcore_sku = item.get("–ê—Ä—Ç–∏–∫—É")
            xcore_price = item.get("–¶—ñ–Ω–∞")

            if not xcore_sku:
                continue

            match_found = False

            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ SKU
            if xcore_sku in data_dict:
                data_dict[xcore_sku]["xcore_sku"] = xcore_sku
                data_dict[xcore_sku]["xcore_price"] = xcore_price
                data_dict[xcore_sku]["matched"] = True
                match_found = True
            else:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º xcore_sku –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                normalized_xcore = normalize_sku(xcore_sku)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É SKU
                if normalized_xcore in normalized_sku_dict:
                    original_sku = normalized_sku_dict[normalized_xcore]
                    data_dict[original_sku]["xcore_sku"] = xcore_sku
                    data_dict[original_sku]["xcore_price"] = xcore_price
                    data_dict[original_sku]["matched"] = True
                    match_found = True

            if not match_found:
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                new_key = f"xcore_{xcore_sku}"
                data_dict[new_key] = {
                    "–ú–æ–π —Å–∞–π—Ç sku": None,
                    "–ú–æ–π —Å–∞–π—Ç ean": None,
                    "–ú–æ–π —Å–∞–π—Ç —Ü–µ–Ω–∞": None,
                    "insportline vendor_code": None,
                    "insportline —Ü–µ–Ω–∞": None,
                    "xcore_sku": xcore_sku,
                    "xcore_price": xcore_price,
                    "matched": False,  # –≠—Ç–æ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å
                }

        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(xcore_data)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ xcore_com_ua.json")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ xcore_com_ua.json: {e}")

    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∏ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ
    for key, value in data_dict.items():
        # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω–æ–µ –ø–æ–ª–µ matched, –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤ result
        matched = value.pop("matched", False)

        # –ó–∞–ø–∏—Å—å —Å—á–∏—Ç–∞–µ—Ç—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π, –µ—Å–ª–∏ –≤ –Ω–µ–π –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ —Ö–æ—Ç—è –±—ã –∏–∑ –¥–≤—É—Ö —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        sources_count = 0
        if value["–ú–æ–π —Å–∞–π—Ç sku"] is not None:
            sources_count += 1
        if value["insportline vendor_code"] is not None:
            sources_count += 1
        if value["xcore_sku"] is not None:
            sources_count += 1

        if sources_count >= 2:
            matched_data.append(value)
        else:
            unmatched_data.append(value)

    # –í—ã–≤–æ–¥–∏–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∏ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    print(f"–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(matched_data)}")
    print(f"–ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(unmatched_data)}")

    # –°–æ–µ–¥–∏–Ω—è–µ–º —Å–Ω–∞—á–∞–ª–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ, –∑–∞—Ç–µ–º –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
    result = matched_data + unmatched_data

    # # –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤—ã–≤–µ–¥–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    # print("\n–ü—Ä–∏–º–µ—Ä—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π:")
    # for i, item in enumerate(matched_data[:5]):  # –ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    #     print(
    #         f"{i+1}. SKU: {item['–ú–æ–π —Å–∞–π—Ç sku']}, "
    #         + f"Insportline: {item['insportline vendor_code']}, "
    #         + f"Xcore: {item['xcore_sku']}, "
    #         + f"–¶–µ–Ω—ã: {item['–ú–æ–π —Å–∞–π—Ç —Ü–µ–Ω–∞']} / {item['insportline —Ü–µ–Ω–∞']} / {item['xcore_price']}"
    #     )

    # –ü–æ–ª—É—á–∞–µ–º –ª–∏—Å—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
    sheet_name = "Data"
    sheet = get_google_sheet(sheet_name)
    update_sheet_with_data(sheet, result)

    return result  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    # # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏
    # result = list(data_dict.values())

    # # –ü–æ–ª—É—á–∞–µ–º –ª–∏—Å—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
    # sheet_name = "Data"
    # sheet = get_google_sheet(sheet_name)
    # update_sheet_with_data(sheet, result)


def normalize_sku(sku):
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç SKU, —É–¥–∞–ª—è—è –ø—Ä–µ—Ñ–∏–∫—Å 'INS' –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å.
    –ù–∞–ø—Ä–∏–º–µ—Ä: 'INS9410-3' -> '9410-3'
    """
    if sku and isinstance(sku, str):
        if sku.startswith("INS"):
            return sku[3:]  # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å–∏–º–≤–æ–ª–∞ (INS)
    return sku


def extract_xml_value(element, tag_name):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ–≥–∞ –∏–∑ XML —ç–ª–µ–º–µ–Ω—Ç–∞ –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 'N/A', –µ—Å–ª–∏ —Ç–µ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω."""
    node = element.find(tag_name)
    return node.text if node is not None else None


def get_sheet_data(sheet_name):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ª–∏—Å—Ç–∞ Google —Ç–∞–±–ª–∏—Ü—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ö –≤ –≤–∏–¥–µ pandas DataFrame."""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ª–∏—Å—Ç
        worksheet = get_google_sheet(sheet_name)

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –ª–∏—Å—Ç–∞
        data = worksheet.get_all_records()

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        df = pd.DataFrame(data)

        logger.info(
            f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–∏—Å—Ç–∞ '{sheet_name}'. –°—Ç—Ä–æ–∫: {len(df)}"
        )
        return df
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ª–∏—Å—Ç–∞ '{sheet_name}': {e}")
        raise


def process_prices(source_sheet_name, result_sheet_name="result"):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ª–∏—Å—Ç–∞, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ü–µ–Ω—ã –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç
    —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ª–∏—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

    :param source_sheet_name: –ò–º—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ª–∏—Å—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
    :param result_sheet_name: –ò–º—è –ª–∏—Å—Ç–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "result")
    :return: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ DataFrame
        df = get_sheet_data(source_sheet_name)

        # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ (—É–±–µ—Ä–µ–º –ø—Ä–æ–±–µ–ª—ã)
        df.columns = [col.replace(" ", "_") for col in df.columns]

        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        result_df = pd.DataFrame(
            columns=[
                "–ê—Ä—Ç–∏–∫—É–ª",
                "—Å—Ç–∞—Ä–∞_—Ü—ñ–Ω–∞",
                "–Ω–æ–≤–∞_—Ü—ñ–Ω–∞",
                "–¶—ñ–Ω–∞_Xcore",
                "–¶—ñ–Ω–∞_Insportline",
            ]
        )

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
        for _, row in df.iterrows():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ (–æ–¥–∏–Ω –∏–∑ —Ç—Ä–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)
            my_sku = str(row["–ú–æ–π_—Å–∞–π—Ç_sku"])
            insportline_code = str(row.get("insportline_vendor_code", ""))
            xcore_sku = str(row.get("xcore_sku", ""))

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ MBS/MS
            if my_sku.startswith("MBS-") and xcore_sku.startswith("MS-"):
                my_sku_normalized = my_sku.replace("MBS-", "")
                xcore_sku_normalized = xcore_sku.replace("MS-", "")
                is_prefix_match = my_sku_normalized == xcore_sku_normalized
            elif my_sku.startswith("MS-") and xcore_sku.startswith("MBS-"):
                my_sku_normalized = my_sku.replace("MS-", "")
                xcore_sku_normalized = xcore_sku.replace("MBS-", "")
                is_prefix_match = my_sku_normalized == xcore_sku_normalized
            else:
                is_prefix_match = False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –µ—Å—Ç—å
            is_match = (
                (my_sku and insportline_code and xcore_sku)  # –≤–∞—Ä–∏–∞–Ω—Ç 1: –≤—Å–µ –∞—Ä—Ç–∏–∫—É–ª—ã
                or (
                    my_sku and my_sku == xcore_sku
                )  # –≤–∞—Ä–∏–∞–Ω—Ç 2: –ú–æ–π —Å–∞–π—Ç sku –∏ xcore_sku
                or (
                    my_sku and my_sku == insportline_code
                )  # –≤–∞—Ä–∏–∞–Ω—Ç 3: –ú–æ–π —Å–∞–π—Ç sku –∏ insportline
                or is_prefix_match  # –≤–∞—Ä–∏–∞–Ω—Ç 4: —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ MBS/MS
            )

            if not is_match:
                continue

            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É –Ω–∞ —Å–∞–π—Ç–µ
            try:
                my_price = (
                    float(row["–ú–æ–π_—Å–∞–π—Ç_—Ü–µ–Ω–∞"])
                    if pd.notna(row.get("–ú–æ–π_—Å–∞–π—Ç_—Ü–µ–Ω–∞"))
                    else 0
                )
            except (ValueError, TypeError):
                my_price = 0

            # –ü–æ–ª—É—á–∞–µ–º —Ü–µ–Ω—ã –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤
            try:
                insportline_price = (
                    float(row.get("insportline_—Ü–µ–Ω–∞", 0))
                    if pd.notna(row.get("insportline_—Ü–µ–Ω–∞"))
                    else 0
                )
            except (ValueError, TypeError):
                insportline_price = 0

            try:
                xcore_price = (
                    float(row.get("xcore_price", 0))
                    if pd.notna(row.get("xcore_price"))
                    else 0
                )
            except (ValueError, TypeError):
                xcore_price = 0

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ü–µ–Ω (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ü–µ–Ω—ã 1 –∏–ª–∏ 2)
            valid_prices = []

            if xcore_price > 2:
                valid_prices.append(xcore_price)

            if insportline_price > 2:
                valid_prices.append(insportline_price)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ü–µ–Ω
            if not valid_prices:
                continue

            # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –≤–∞–ª–∏–¥–Ω—É—é —Ü–µ–Ω—É —Å —É—á–µ—Ç–æ–º —É—Å–ª–æ–≤–∏–π
            filtered_prices = valid_prices.copy()

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ü–µ–Ω—ã, –µ—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –Ω–∏–º–∏ –±–æ–ª–µ–µ 50%
            if len(valid_prices) > 1:
                min_price = min(valid_prices)
                max_price = max(valid_prices)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ü–µ–Ω–æ–π
                if max_price / min_price > 1.5:  # —Ä–∞–∑–Ω–∏—Ü–∞ –±–æ–ª–µ–µ 50%
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫—É—é —Ü–µ–Ω—É –∏—Å–∫–ª—é—á–∏—Ç—å
                    if (
                        xcore_price in valid_prices
                        and insportline_price in valid_prices
                    ):
                        # –ï—Å–ª–∏ –æ–±–µ —Ü–µ–Ω—ã –≤–∞–ª–∏–¥–Ω—ã, —É–¥–∞–ª—è–µ–º –≤—ã–±—Ä–æ—Å
                        if xcore_price / insportline_price > 1.5:
                            filtered_prices.remove(xcore_price)
                        elif insportline_price / xcore_price > 1.5:
                            filtered_prices.remove(insportline_price)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª—É—á–∞–π, –∫–æ–≥–¥–∞ —Ü–µ–Ω–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –Ω–∏–∂–µ –Ω–∞—à–µ–π –Ω–∞ 30% –∏ –±–æ–ª–µ–µ
            if my_price > 0:
                for price in valid_prices[:]:  # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
                    if (
                        price / my_price < 0.7
                    ):  # –¶–µ–Ω–∞ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –Ω–∏–∂–µ –Ω–∞—à–µ–π –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 30%
                        if price in filtered_prices:
                            filtered_prices.remove(price)

            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–∏—Å—å —Ü–µ–Ω—ã
            # –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ–º —Å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º —Å–ø–∏—Å–∫–æ–º
            if filtered_prices:
                min_supplier_price = min(filtered_prices)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –Ω–∞—à–∞ —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞ —Å–∞–º–æ–π –Ω–∏–∑–∫–æ–π
                if my_price > 0 and my_price < min_supplier_price:
                    # –ï—Å–ª–∏ –Ω–∞—à–∞ —Ü–µ–Ω–∞ –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤, –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞—à—É —Ü–µ–Ω—É
                    new_price = my_price
                else:
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–æ–≤—É—é —Ü–µ–Ω—É —Å –Ω–µ–±–æ–ª—å—à–∏–º —Å–ª—É—á–∞–π–Ω—ã–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ–º
                    discount_factor = round(random.uniform(0.95, 0.97), 2)
                    new_price = min_supplier_price * discount_factor

                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                result_df = result_df._append(
                    {
                        "–ê—Ä—Ç–∏–∫—É–ª": my_sku,
                        "—Å—Ç–∞—Ä–∞_—Ü—ñ–Ω–∞": my_price,
                        "–Ω–æ–≤–∞_—Ü—ñ–Ω–∞": round(new_price, 2),
                        "–¶—ñ–Ω–∞_Xcore": xcore_price if xcore_price > 2 else "-",
                        "–¶—ñ–Ω–∞_Insportline": (
                            insportline_price if insportline_price > 2 else "-"
                        ),
                    },
                    ignore_index=True,
                )
            else:
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –≤–∞–ª–∏–¥–Ω—ã—Ö —Ü–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à—É —Ü–µ–Ω—É
                new_price = my_price

        # –í—ã–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ª–∏—Å—Ç "result" –∏—Å–ø–æ–ª—å–∑—É—è —Ñ—É–Ω–∫—Ü–∏—é update_sheet_with_data
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ª–∏—Å—Ç –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            result_sheet = get_google_sheet(result_sheet_name)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º DataFrame –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ —Ñ—É–Ω–∫—Ü–∏—é update_sheet_with_data
            # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º —Å—Ç–æ–ª–±—Ü—ã –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü–µ
            result_df_renamed = result_df.rename(
                columns={
                    "–ê—Ä—Ç–∏–∫—É–ª": "–ê—Ä—Ç–∏–∫—É–ª",
                    "—Å—Ç–∞—Ä–∞_—Ü—ñ–Ω–∞": "—Å—Ç–∞—Ä–∞ —Ü—ñ–Ω–∞",
                    "–Ω–æ–≤–∞_—Ü—ñ–Ω–∞": "–Ω–æ–≤–∞ —Ü—ñ–Ω–∞",
                    "–¶—ñ–Ω–∞_Xcore": "–¶—ñ–Ω–∞ Xcore",
                    "–¶—ñ–Ω–∞_Insportline": "–¶—ñ–Ω–∞ Insportline",
                }
            )

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º DataFrame –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            result_data = result_df_renamed.to_dict("records")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–∏—Å—Ç–∞
            update_sheet_with_data(result_sheet, result_data)

            logger.info(
                f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(result_df)} —Ç–æ–≤–∞—Ä–æ–≤. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–≥—Ä—É–∂–µ–Ω—ã –≤ –ª–∏—Å—Ç '{result_sheet_name}'."
            )
        except Exception as e:
            logger.error(
                f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ª–∏—Å—Ç '{result_sheet_name}': {e}"
            )
            raise

        return result_df

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise


if __name__ == "__main__":
    download_all_xml_files()
    parsin_xml()
    source_sheet = "Data"  # –ò–º—è –ª–∏—Å—Ç–∞ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    result_sheet = "result"  # –ò–º—è –ª–∏—Å—Ç–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results = process_prices(source_sheet, result_sheet)
