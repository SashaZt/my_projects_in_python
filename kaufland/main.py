# –†–∞–±–æ—á–∏–π –∫–æ–¥ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å html —Ñ–∞–π–ª–æ–≤

import json
import re
import sys
from pathlib import Path

from loguru import logger

current_directory = Path.cwd()
log_directory = current_directory / "log"
json_directory = current_directory / "json"
log_directory.mkdir(parents=True, exist_ok=True)
json_directory.mkdir(parents=True, exist_ok=True)

log_file_path = log_directory / "log_message.log"
logger.remove()
# üîπ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª
logger.add(
    log_file_path,
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {line} | {message}",
    level="DEBUG",
    encoding="utf-8",
    rotation="10 MB",
    retention="7 days",
)

# üîπ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å (—Ü–≤–µ—Ç–Ω–æ–π –≤—ã–≤–æ–¥)
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{line}</cyan> | <cyan>{message}</cyan>",
    level="DEBUG",
    enqueue=True,
)


def extract_script_content(file_path):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫—Ä–∏–ø—Ç–∞ —Å APP_SHELL_SSR_STATE –∏–∑ HTML —Ñ–∞–π–ª–∞

    Args:
        file_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É HTML –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ HTML

    Returns:
        str: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫—Ä–∏–ø—Ç–∞
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ input —Ñ–∞–π–ª–æ–º –∏–ª–∏ —Å—Ç—Ä–æ–∫–æ–π HTML
        if file_path.endswith(".html") or file_path.endswith(".txt"):
            with open(file_path, "r", encoding="utf-8") as file:
                content = file.read()
        else:
            content = file_path

        # –ù–∞–π—Ç–∏ JavaScript –≤ —Ç–µ–≥–∞—Ö script
        pattern = r'<script>(window\["APP_SHELL_SSR_STATE_@mf\\u002Fpdp-frontend"\].*?)<\/script>'
        match = re.search(pattern, content, re.DOTALL)

        if match:
            return match.group(1)
        else:
            return None
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–≤–æ–¥–∞: {e}")
        return None


def extract_image_hashes(script_content):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–µ—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞

    Args:
        script_content (str): –°–æ–¥–µ—Ä–∂–∏–º–æ–µ JavaScript

    Returns:
        list: –°–ø–∏—Å–æ–∫ —Ö–µ—à–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –≤—ã–∑–æ–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏
    end_pattern = r"\}\((.*?)\)\);$"
    match = re.search(end_pattern, script_content)
    if not match:
        return []

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    params_str = match.group(1)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ö–µ—à–∏ (—Å—Ç—Ä–æ–∫–∏ –∏–∑ 32 —Å–∏–º–≤–æ–ª–æ–≤ –≤ —à–µ—Å—Ç–Ω–∞–¥—Ü–∞—Ç–µ—Ä–∏—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ)
    hash_pattern = r'"([a-f0-9]{32})"'
    hash_matches = re.finditer(hash_pattern, params_str)

    hashes = [
        f"https://media.cdn.kaufland.de/product-images/1024x1024/{match.group(1)}.webp"
        for match in hash_matches
    ]
    return hashes


def parse_js_assignment(js_code):
    """
    –ü–∞—Ä—Å–∏—Ç JavaScript-–≤—ã—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ

    Args:
        js_code (str): JavaScript-–∫–æ–¥ —Å –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è

    Returns:
        dict: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ JavaScript-–æ–±—ä–µ–∫—Ç–∞
    """
    # –ò–∑–≤–ª–µ—á—å IIFE (Immediately Invoked Function Expression)
    iife_pattern = r'window\["APP_SHELL_SSR_STATE_@mf\\u002Fpdp-frontend"\] = \(function\((.*?)\)\{(.*?)return (.*?)\}\((.*?)\)\);'
    match = re.search(iife_pattern, js_code, re.DOTALL)

    if not match:
        return None

    # –ü–æ–ª—É—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Ç–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç –∏ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    parameters = match.group(1).split(",")
    function_body = match.group(2)
    return_object = match.group(3)
    args = match.group(4).split(",")

    # –°–æ–∑–¥–∞—Ç—å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    param_map = {}
    for i, param in enumerate(parameters):
        if i < len(args):
            param_map[param.strip()] = args[i].strip()

    # –ò–∑–≤–ª–µ—á—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–ª–∞ —Ñ—É–Ω–∫—Ü–∏–∏
    var_defs = {}
    var_pattern = r"B\.(\w+)=(.*?);"
    var_matches = re.finditer(var_pattern, function_body)

    for var_match in var_matches:
        var_name = var_match.group(1)
        var_value = var_match.group(2)

        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —á–∏—Å–ª–∞
            if var_value.replace(".", "", 1).isdigit():
                var_defs[var_name] = (
                    float(var_value) if "." in var_value else int(var_value)
                )
            # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            elif var_value in param_map:
                var_defs[var_name] = param_map[var_value]
            else:
                var_defs[var_name] = var_value
        except:
            var_defs[var_name] = var_value

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–∞
    product_info = {
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        "offerNetPrice": var_defs.get("offerNetPrice"),
        "sellerId": var_defs.get("sellerId"),
        "offerId": var_defs.get("offerId"),
        "categoryId": var_defs.get("categoryId"),
        "itemId": var_defs.get("itemId"),
        "isDirectSales": var_defs.get("isDirectSales"),
    }

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ return_object
    try:
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–≤–∞—Ä–µ
        title_pattern = r'title:"([^"]+)"'
        title_match = re.search(title_pattern, return_object)
        if title_match:
            product_info["title"] = title_match.group(1)

        # –¶–µ–Ω–∞
        price_pattern = r"price:([\d.]+)"
        price_match = re.search(price_pattern, return_object)
        if price_match:
            product_info["price"] = float(price_match.group(1))

        # –í–∞–ª—é—Ç–∞
        currency_pattern = r'currency:"([^"]+)"'
        currency_match = re.search(currency_pattern, return_object)
        if currency_match:
            product_info["currency"] = currency_match.group(1)

        # –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞
        description_pattern = r'descriptionHtml:"([^"]+)"'
        description_match = re.search(description_pattern, return_object)
        if description_match:
            product_info["description"] = (
                description_match.group(1)
                .replace("\\u003C", "<")
                .replace("\\u003E", ">")
                .replace("\\u002F", "/")
            )

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç–∞–≤–∫–µ
        delivery_date_pattern = r'datePhrase:"([^"]+)"'
        delivery_date_match = re.search(delivery_date_pattern, return_object)
        if delivery_date_match:
            product_info["deliveryDate"] = delivery_date_match.group(1)

        delivery_time_pattern = r'deliveryTime:"([^"]+)"'
        delivery_time_match = re.search(delivery_time_pattern, return_object)
        if delivery_time_match:
            product_info["deliveryTime"] = delivery_time_match.group(1)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        main_category_title_pattern = r"mainCategoryTitle:([^,}]+)"
        main_category_title_match = re.search(
            main_category_title_pattern, return_object
        )
        if main_category_title_match:
            # –û—á–∏—Å—Ç–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            cat_title = main_category_title_match.group(1).strip()
            if cat_title in param_map:
                product_info["mainCategoryTitle"] = param_map[cat_title].strip('"')
            else:
                product_info["mainCategoryTitle"] = cat_title.strip('"')

        # URL —Ç–æ–≤–∞—Ä–∞
        path_pattern = r'virtualProductPath:"([^"]+)"'
        path_match = re.search(path_pattern, return_object)
        if path_match:
            product_info["productPath"] = path_match.group(1).replace("\\u002F", "/")

        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å
        manufacturer_pattern = r"name:([^,}]+),logoUrl:"
        manufacturer_match = re.search(manufacturer_pattern, return_object)
        if manufacturer_match:
            manufacturer = manufacturer_match.group(1).strip()
            if manufacturer in param_map:
                product_info["manufacturer"] = param_map[manufacturer].strip('"')
            else:
                product_info["manufacturer"] = manufacturer.strip('"')

        # EAN –∏ –¥—Ä—É–≥–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        ean_pattern = r'EAN",values:\[\{text:"([^"]+)"\}\]'
        ean_match = re.search(ean_pattern, return_object)
        if ean_match:
            product_info["ean"] = ean_match.group(1)
        else:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ EAN
            alt_ean_pattern = (
                r'"0\d{12,13}"'  # EAN –æ–±—ã—á–Ω–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0 –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç 13-14 —Ü–∏—Ñ—Ä
            )
            alt_ean_match = re.search(alt_ean_pattern, return_object)
            if alt_ean_match:
                product_info["ean"] = alt_ean_match.group(0).strip('"')

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–¥–∞–≤—Ü–µ
        seller_name_pattern = r'name:"([^"]+)",legalData:'
        seller_name_match = re.search(seller_name_pattern, return_object)
        if seller_name_match:
            product_info["sellerName"] = seller_name_match.group(1)

        shop_link_pattern = r'shopLink:"([^"]+)"'
        shop_link_match = re.search(shop_link_pattern, return_object)
        if shop_link_match:
            product_info["shopLink"] = shop_link_match.group(1).replace("\\u002F", "/")

        # –°—Ä–æ–∫ –≤–æ–∑–≤—Ä–∞—Ç–∞
        return_period_pattern = r'returnPeriod:"([^"]+)"'
        return_period_match = re.search(return_period_pattern, return_object)
        if return_period_match:
            product_info["returnPeriod"] = return_period_match.group(1)

        # –î–æ—Å—Ç—É–ø–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        amount_left_pattern = r"amountLeft:(\d+),"
        amount_left_match = re.search(amount_left_pattern, return_object)
        if amount_left_match:
            product_info["amountLeft"] = int(amount_left_match.group(1))

        # –•–ª–µ–±–Ω—ã–µ –∫—Ä–æ—à–∫–∏
        breadcrumb_pattern = r'\{id:(\d+),title:"([^"]+)",name:"([^"]+)",url:"([^"]+)"'
        breadcrumb_matches = re.finditer(breadcrumb_pattern, return_object)
        breadcrumbs = []
        for match in breadcrumb_matches:
            breadcrumbs.append(
                {
                    "id": match.group(1),
                    "title": match.group(2),
                    "name": match.group(3),
                    "url": match.group(4).replace("\\u002F", "/"),
                }
            )
        product_info["breadcrumbs"] = breadcrumbs

        # –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–µ –ª–∏—Ü–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–ø–∞–Ω–∏–∏)
        responsible_pattern = r'name:"([^"]+)",address:"([^"]+)",email:"([^"]+)"'
        responsible_match = re.search(responsible_pattern, return_object)
        if responsible_match:
            product_info["responsiblePeople"] = {
                "name": responsible_match.group(1),
                "address": responsible_match.group(2).replace("\\n", "\n"),
                "email": responsible_match.group(3),
            }

        # –†–µ–π—Ç–∏–Ω–≥ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
        reviews_pattern = r"numberOfReviews:(\d+),numberOfStars:(\d+)"
        reviews_match = re.search(reviews_pattern, return_object)
        if reviews_match:
            product_info["reviews"] = {
                "count": int(reviews_match.group(1)),
                "stars": int(reviews_match.group(2)),
            }

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç–∞–≤–∫–µ
        country_pattern = r'country:"([^"]+)",countryISO:"([^"]+)"'
        country_match = re.search(country_pattern, return_object)
        if country_match:
            product_info["deliveryCountry"] = {
                "name": country_match.group(1),
                "iso": country_match.group(2),
            }

        # –î–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏ –¥–æ—Å—Ç–∞–≤–∫–∏
        delivery_range_pattern = r'min:"([^"]+)",max:"([^"]+)"'
        delivery_range_match = re.search(delivery_range_pattern, return_object)
        if delivery_range_match:
            product_info["deliveryTimeRange"] = {
                "min": delivery_range_match.group(1),
                "max": delivery_range_match.group(2),
            }

    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—ä–µ–∫—Ç–∞: {e}")

    return product_info


def extract_product_data(input_content, output_file=None):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ –∏–∑ HTML —Ñ–∞–π–ª–∞ –∏–ª–∏ —Å—Ç—Ä–æ–∫–∏ HTML –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ JSON

    Args:
        input_content (str): –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å HTML —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
        output_file (str, optional): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON

    Returns:
        dict: –î–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ
    """
    # –ò–∑–≤–ª–µ—á—å —Å–∫—Ä–∏–ø—Ç
    script_content = extract_script_content(input_content)

    if not script_content:
        logger.warning("–°–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º.")
        return None

    # –†–∞–∑–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
    product_data = parse_js_assignment(script_content)
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–µ—à–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ IIFE
    direct_image_hashes = extract_image_hashes(script_content)
    if direct_image_hashes:
        product_data["directImageHashes"] = direct_image_hashes
    if not product_data:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞.")
        return None
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω output_file
    if output_file:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(product_data, f, ensure_ascii=False, indent=4)
        logger.info(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")

    return product_data


def parse_to_custom_structure(input_file):
    """
    –ü–∞—Ä—Å–∏—Ç HTML —Ñ–∞–π–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∑–∞–¥–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ JSON

    Args:
        input_file (str): –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É
        output_file (str, optional): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é "product.json"

    Returns:
        dict: –î–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ –≤ –∑–∞–¥–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
    """
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏
    product_data = extract_product_data(input_file)

    if not product_data:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ")
        return None
    ean = product_data.get("ean", "")
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é
    custom_structure = {
        "ean": [product_data.get("ean", "")],
        "attributes": {
            "title": [product_data.get("title", "")],
            "manufacturer": [product_data.get("manufacturer", "")],
            "category": [product_data.get("mainCategoryTitle", "")],
            "description": [product_data.get("description", "")],
            "picture": [],
        },
    }

    # –î–æ–±–∞–≤–ª—è–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –µ—Å–ª–∏ –æ–Ω–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
    if "directImageHashes" in product_data and product_data["directImageHashes"]:
        custom_structure["attributes"]["picture"] = product_data["directImageHashes"]

    json_file = json_directory / f"{ean}.json"
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–∞–π–ª
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(custom_structure, f, ensure_ascii=False, indent=4)

    logger.info(f"–î–∞–Ω–Ω—ã–µ –≤ –∫–∞—Å—Ç–æ–º–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {json_file}")

    return custom_structure


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    input_file = "product.html"  # –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É
    output_file = "product_data.json"  # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    # –ü–æ–ª–Ω–µ—ã–π –ø–∞—Ä—Å–µ—Ä html—Ñ–∞–π–ª–∞
    # product_data = extract_product_data(input_file, output_file)

    ## –ì–æ—Ç–æ–≤–∏—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ API
    parse_to_custom_structure(input_file)
