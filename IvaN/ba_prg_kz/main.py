import concurrent.futures
import json
import queue
import random
import sys
import threading
import time
from pathlib import Path

import pandas as pd
import requests
from loguru import logger

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
MAX_RETRIES = 10  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
RETRY_DELAY = 5  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

current_directory = Path.cwd()
json_directory = current_directory / "json"
data_directory = current_directory / "data"
log_directory = current_directory / "log"
data_directory.mkdir(parents=True, exist_ok=True)
log_directory.mkdir(parents=True, exist_ok=True)
json_directory.mkdir(parents=True, exist_ok=True)

input_csv_file = data_directory / "output.csv"
log_file_path = log_directory / "log_message.log"
proxy_file = data_directory / "proxy.txt"  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–æ–∫—Å–∏

logger.remove()
# üîπ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª
logger.add(
    log_file_path,
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {line} | {message}",
    level="DEBUG",
    encoding="utf-8",
    rotation="10 MB",
    retention="7 days",
)

# üîπ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å (—Ü–≤–µ—Ç–Ω–æ–π –≤—ã–≤–æ–¥)
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level}</level> | <cyan>{line}</cyan> | <cyan>{message}</cyan>",
    level="DEBUG",
    enqueue=True,
)

# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ headers –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –≥–¥–µ-—Ç–æ –≤ –≤–∞—à–µ–º –∫–æ–¥–µ
headers = {
    "accept": "*/*",
    "accept-language": "ru,en;q=0.9,uk;q=0.8",
    "dnt": "1",
    "origin": "https://ba.prg.kz",
    "priority": "u=1, i",
    "referer": "https://ba.prg.kz/",
    "sec-ch-ua": '"Not(A:Brand";v="99", "Google Chrome";v="133", "Chromium";v="133"',
    "sec-ch-ua-mobile": "?0",
    "sec-ch-ua-platform": '"Windows"',
    "sec-fetch-dest": "empty",
    "sec-fetch-mode": "cors",
    "sec-fetch-site": "cross-site",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36",
}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ (–±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –≤—Å–µ–º –ø–æ—Ç–æ–∫–∞–º)
ALL_PROXIES = []


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞
def load_proxies():
    if not proxy_file.exists():
        logger.warning(
            f"–§–∞–π–ª —Å –ø—Ä–æ–∫—Å–∏ {proxy_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ"
        )
        return []

    try:
        with open(proxy_file, "r") as f:
            proxies = [line.strip() for line in f if line.strip()]

        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(proxies)} –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞")
        return proxies
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Å –ø—Ä–æ–∫—Å–∏: {str(e)}")
        return []


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–∫—Å–∏ –∏–∑ —Å–ø–∏—Å–∫–∞
def get_random_proxy():
    if not ALL_PROXIES:
        return None
    return random.choice(ALL_PROXIES)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è ID –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ CSV —Ñ–∞–π–ª–∞
def read_companies_from_csv(input_csv_file):
    df = pd.read_csv(input_csv_file)
    return df["bin"].tolist()


# –§—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∫—Å–∏
def get_json(id_company, q):
    file_name = json_directory / f"{id_company}.json"

    # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    if file_name.exists():
        logger.warning(f"–§–∞–π–ª –¥–ª—è ID {id_company} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        q.task_done()
        return

    retry_count = 0

    while retry_count < MAX_RETRIES:
        # –î–ª—è –∫–∞–∂–¥–æ–π –ø–æ–ø—ã—Ç–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏
        proxy = get_random_proxy()
        proxies = None

        if proxy:
            proxies = {"http": proxy, "https": proxy}
            logger.debug(
                f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏ {proxy} –¥–ª—è ID {id_company} (–ø–æ–ø—ã—Ç–∫–∞ {retry_count+1})"
            )

        try:
            params = {
                "id": id_company,
                "lang": "ru",
            }

            response = requests.get(
                "https://apiba.prgapp.kz/CompanyFullInfo",
                params=params,
                headers=headers,
                proxies=proxies,
                timeout=30,
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
            if response.status_code == 200:
                try:
                    data = response.json()
                    with open(file_name, "w", encoding="utf-8") as f:
                        json.dump(data, f, ensure_ascii=False, indent=4)
                    if proxy:
                        logger.info(
                            f"–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∞–π–ª –¥–ª—è ID {id_company} (–ø—Ä–æ–∫—Å–∏: {proxy})"
                        )
                    else:
                        logger.info(
                            f"–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∞–π–ª –¥–ª—è ID {id_company} (–±–µ–∑ –ø—Ä–æ–∫—Å–∏)"
                        )
                    q.task_done()
                    return
                except ValueError:
                    logger.error(f"–û—à–∏–±–∫–∞: –æ—Ç–≤–µ—Ç –¥–ª—è ID {id_company} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç JSON")
            else:
                if proxy:
                    logger.error(
                        f"–û—à–∏–±–∫–∞ –¥–ª—è ID {id_company}: —Å—Ç–∞—Ç—É—Å {response.status_code} (–ø—Ä–æ–∫—Å–∏: {proxy})"
                    )
                else:
                    logger.error(
                        f"–û—à–∏–±–∫–∞ –¥–ª—è ID {id_company}: —Å—Ç–∞—Ç—É—Å {response.status_code} (–±–µ–∑ –ø—Ä–æ–∫—Å–∏)"
                    )

            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ 200 –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON
            retry_count += 1
            logger.warning(
                f"–ü–æ–ø—ã—Ç–∫–∞ {retry_count}/{MAX_RETRIES} –¥–ª—è ID {id_company}, –ø–∞—É–∑–∞ {RETRY_DELAY} —Å–µ–∫."
            )
            time.sleep(RETRY_DELAY)

        except requests.exceptions.RequestException as e:
            if proxy:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è ID {id_company} (–ø—Ä–æ–∫—Å–∏: {proxy}): {str(e)}"
                )
            else:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è ID {id_company} (–±–µ–∑ –ø—Ä–æ–∫—Å–∏): {str(e)}"
                )

            retry_count += 1
            logger.error(
                f"–ü–æ–ø—ã—Ç–∫–∞ {retry_count}/{MAX_RETRIES} –¥–ª—è ID {id_company}, –ø–∞—É–∑–∞ {RETRY_DELAY} —Å–µ–∫."
            )
            time.sleep(RETRY_DELAY)

    logger.warning(f"–ò—Å—á–µ—Ä–ø–∞–Ω—ã –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –¥–ª—è ID {id_company}")
    q.task_done()


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –ø–æ—Ç–æ–∫–∞
def worker(q, thread_id):
    logger.info(f"–ó–∞–ø—É—â–µ–Ω –ø–æ—Ç–æ–∫ {thread_id}")

    while True:
        id_company = q.get()
        if id_company is None:  # –°–∏–≥–Ω–∞–ª –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞
            q.task_done()
            break
        get_json(id_company, q)


# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def process_companies(num_threads=5):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–∫—Å–∏ –≤ –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
    global ALL_PROXIES
    ALL_PROXIES = load_proxies()

    if ALL_PROXIES:
        logger.info(f"–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {len(ALL_PROXIES)} —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤")
    else:
        logger.info("–ü—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ")

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ ID –∫–æ–º–ø–∞–Ω–∏–π
    company_ids = read_companies_from_csv(input_csv_file)
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(company_ids)} ID –∫–æ–º–ø–∞–Ω–∏–π")

    # –°–æ–∑–¥–∞–µ–º –æ—á–µ—Ä–µ–¥—å –∏ –ø–æ—Ç–æ–∫–∏
    q = queue.Queue()
    threads = []

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞–±–æ—á–∏–µ –ø–æ—Ç–æ–∫–∏
    for i in range(num_threads):
        t = threading.Thread(target=worker, args=(q, i))
        t.daemon = True
        t.start()
        threads.append(t)

    # –î–æ–±–∞–≤–ª—è–µ–º ID –∫–æ–º–ø–∞–Ω–∏–π –≤ –æ—á–µ—Ä–µ–¥—å
    for id_company in company_ids:
        q.put(id_company)

    # –î–æ–∂–∏–¥–∞–µ–º—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏
    q.join()

    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–∏
    for i in range(num_threads):
        q.put(None)

    # –î–æ–∂–∏–¥–∞–µ–º—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
    for t in threads:
        t.join()

    logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


# def format_value(value):
#     if value is True:
#         return "–î–∞"
#     elif value is False:
#         return "–ù–µ—Ç"
#     else:
#         return value


# def process_data():
#     all_data = []
#     for json_file in json_directory.glob("*.json"):
#         with open(json_file, "r", encoding="utf-8") as file:
#             data = json.load(file)
#         company_bin = data.get("basicInfo", {}).get("bin", None)
#         isNds_raw = data.get("basicInfo", {}).get("isNds", {}).get("value", None)
#         if isNds_raw is True:
#             isNds = "–î–∞"
#         else:
#             isNds = "–ù–µ—Ç"
#         degreeOfRisk = (
#             data.get("basicInfo", {}).get("degreeOfRisk", {}).get("value", None)
#         )
#         egov_contacts = data.get("egovContacts", {})
#         phone_list = egov_contacts.get("phone", [])
#         phone_value = phone_list[0].get("value", None) if phone_list else None
#         gosZakupContacts = data.get("gosZakupContacts", {})
#         phone_list_goz = gosZakupContacts.get("phone", [])
#         email_list_goz = gosZakupContacts.get("email", [])
#         www_list_goz = gosZakupContacts.get("website", [])
#         phone_value_goz = (
#             phone_list_goz[0].get("value", None) if phone_list_goz else None
#         )
#         email_value_goz = (
#             email_list_goz[0].get("value", None) if email_list_goz else None
#         )
#         www_value_goz = www_list_goz[0].get("value", None) if www_list_goz else None
#         debtsInfo = data.get("debtsInfo", {})
#         kgd = debtsInfo.get("kgd", {}).get("totalDebt", None)
#         egov = debtsInfo.get("egov", {}).get("totalDebt", None)

#         reestrs = data.get("reestrs", [])

#         # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
#         table_reestrs = {}
#         # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –±—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

#         # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É —Å–ø–∏—Å–∫–∞
#         for item in reestrs:
#             description = item.get("description", "").replace(
#                 "–ö–æ–º–∏—Ç–µ—Ç –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ—Ö–æ–¥–æ–≤ : ", ""
#             )

#             # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏–π, –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
#             priority_keys = ["isIntruder", "isNDS", "risk", "violation", "debtSumm"]

#             # –ù–∞–π–¥–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –∫–ª—é—á
#             for key in priority_keys:
#                 if key in item:
#                     # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
#                     table_reestrs[description] = format_value(item.get(key))
#                     break
#         taxes = data.get("taxes", {})
#         checkDate = taxes.get("checkDate", None)
#         taxGraph = taxes.get("taxGraph", [])
#         # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –≥–æ–¥: –∑–Ω–∞—á–µ–Ω–∏–µ
#         tax_by_year = {}

#         # –ì–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–º –Ω—É–∂–Ω—ã
#         needed_years = [2021, 2022, 2023, 2024]

#         for item in taxGraph:
#             year = item.get("year")
#             value = item.get("value")
#             if year in needed_years:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≥–æ–¥ –≤ –Ω–∞—à–µ–º —Å–ø–∏—Å–∫–µ –Ω—É–∂–Ω—ã—Ö –≥–æ–¥–æ–≤
#                 tax_by_year[year] = value
#         result = {
#             "–ë–ò–ù": company_bin,
#             "–ü–ª–∞—Ç–µ–ª—å—â–∏–∫ –ù–î–°": isNds,
#             "–°—Ç–µ–ø–µ–Ω—å —Ä–∏—Å–∫–∞ –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞": degreeOfRisk,
#             "–¢–µ–ª–µ—Ñ–æ–Ω": phone_value,
#             "–¢–µ–ª–µ—Ñ–æ–Ω –≥–æc. –∑–∞–∫—É–ø–æ–∫": phone_value_goz,
#             "E-mail –≥–æc. –∑–∞–∫—É–ø–æ–∫": email_value_goz,
#             "–í–µ–±-—Å–∞–π—Ç –≥–æc. –∑–∞–∫—É–ø–æ–∫": www_value_goz,
#             "–ó–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –ö–æ–º–∏—Ç–µ—Ç –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ—Ö–æ–¥–æ–≤": kgd,
#             "–ó–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–µ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ": egov,
#             "–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è": table_reestrs,
#             "–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ:–ö–æ–º–∏—Ç–µ—Ç –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ—Ö–æ–¥–æ–≤: —É–ø–ª–∞—Ç–∞ –Ω–∞–ª–æ–≥–æ–≤": checkDate,
#             "–ù–∞–ª–æ–≥–æ–≤—ã–µ –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è": tax_by_year,
#         }

#         all_data.append(result)

#     return all_data


# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤–∞—Ä–µ–π –≤ –ø–ª–æ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
# def flatten_nested_data(data_list):
#     flattened_data = []

#     for item in data_list:
#         flat_item = {}

#         # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø–æ–ª—è
#         for key, value in item.items():
#             if not isinstance(value, dict):
#                 flat_item[key] = value

#         # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º "–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è"
#         if "–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è" in item:
#             for subkey, subvalue in item["–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è"].items():
#                 flat_item[f"–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å_{subkey}"] = subvalue

#         # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º "–ù–∞–ª–æ–≥–æ–≤—ã–µ –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è"
#         if "–ù–∞–ª–æ–≥–æ–≤—ã–µ –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è" in item:
#             for year, amount in item["–ù–∞–ª–æ–≥–æ–≤—ã–µ –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è"].items():
#                 flat_item[f"–ù–∞–ª–æ–≥–∏_{year}"] = amount

#         flattened_data.append(flat_item)

#     return flattened_data


# def write_csv(data):
#     # –°–æ–∑–¥–∞–µ–º DataFrame
#     df = pd.DataFrame(data)

#     # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
#     df.to_csv("company_data.csv", index=False, encoding="utf-8")


def format_value(value):
    if value is True:
        return "–î–∞"
    elif value is False:
        return "–ù–µ—Ç"
    else:
        return value


def process_single_file(json_file):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω JSON-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
    try:
        with open(json_file, "r", encoding="utf-8") as file:
            data = json.load(file)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ data –Ω–µ None
        if data is None:
            logger.error(f"–î–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª–µ {json_file} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
            return None

        # –ü–æ–ª—É—á–∞–µ–º basicInfo —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        basicInfo = data.get("basicInfo", {})
        if basicInfo is None:
            basicInfo = {}

        company_bin = basicInfo.get("bin", None)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ isNds
        isNds_obj = basicInfo.get("isNds")
        if isNds_obj is None:
            isNds = "–ù–µ—Ç"
        else:
            isNds_raw = isNds_obj.get("value", None)
            if isNds_raw is True:
                isNds = "–î–∞"
            else:
                isNds = "–ù–µ—Ç"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ degreeOfRisk
        degreeOfRisk_obj = basicInfo.get("degreeOfRisk")
        if degreeOfRisk_obj is None:
            degreeOfRisk = None
        else:
            degreeOfRisk = degreeOfRisk_obj.get("value", None)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ egovContacts
        egov_contacts = data.get("egovContacts", {})
        if egov_contacts is None:
            egov_contacts = {}

        phone_list = egov_contacts.get("phone", [])
        if phone_list is None:
            phone_list = []

        phone_value = phone_list[0].get("value", None) if phone_list else None

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ gosZakupContacts
        gosZakupContacts = data.get("gosZakupContacts", {})
        if gosZakupContacts is None:
            gosZakupContacts = {}

        phone_list_goz = gosZakupContacts.get("phone", [])
        if phone_list_goz is None:
            phone_list_goz = []

        email_list_goz = gosZakupContacts.get("email", [])
        if email_list_goz is None:
            email_list_goz = []

        www_list_goz = gosZakupContacts.get("website", [])
        if www_list_goz is None:
            www_list_goz = []

        phone_value_goz = (
            phone_list_goz[0].get("value", None) if phone_list_goz else None
        )
        email_value_goz = (
            email_list_goz[0].get("value", None) if email_list_goz else None
        )
        www_value_goz = www_list_goz[0].get("value", None) if www_list_goz else None

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ debtsInfo
        debtsInfo = data.get("debtsInfo", {})
        if debtsInfo is None:
            debtsInfo = {}

        kgd_obj = debtsInfo.get("kgd", {})
        if kgd_obj is None:
            kgd_obj = {}

        egov_obj = debtsInfo.get("egov", {})
        if egov_obj is None:
            egov_obj = {}

        kgd = kgd_obj.get("totalDebt", None)
        egov = egov_obj.get("totalDebt", None)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ reestrs
        reestrs = data.get("reestrs", [])
        if reestrs is None:
            reestrs = []

        table_reestrs = {}

        for item in reestrs:
            if item is None:
                continue

            description = item.get("description", "")
            if description is None:
                description = ""
            else:
                description = description.replace(
                    "–ö–æ–º–∏—Ç–µ—Ç –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ—Ö–æ–¥–æ–≤ : ", ""
                )

            priority_keys = ["isIntruder", "isNDS", "risk", "violation", "debtSumm"]

            for key in priority_keys:
                if key in item:
                    table_reestrs[description] = format_value(item.get(key))
                    break

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ taxes
        taxes = data.get("taxes", {})
        if taxes is None:
            taxes = {}

        checkDate = taxes.get("checkDate", None)
        taxGraph = taxes.get("taxGraph", [])
        if taxGraph is None:
            taxGraph = []

        tax_by_year = {}
        needed_years = [2021, 2022, 2023, 2024]

        for item in taxGraph:
            if item is None:
                continue

            year = item.get("year")
            value = item.get("value")
            if year in needed_years:
                tax_by_year[year] = value

        result = {
            "–ë–ò–ù": company_bin,
            "–ü–ª–∞—Ç–µ–ª—å—â–∏–∫ –ù–î–°": isNds,
            "–°—Ç–µ–ø–µ–Ω—å —Ä–∏—Å–∫–∞ –Ω–∞–ª–æ–≥–æ–ø–ª–∞—Ç–µ–ª—å—â–∏–∫–∞": degreeOfRisk,
            "–¢–µ–ª–µ—Ñ–æ–Ω": phone_value,
            "–¢–µ–ª–µ—Ñ–æ–Ω –≥–æc. –∑–∞–∫—É–ø–æ–∫": phone_value_goz,
            "E-mail –≥–æc. –∑–∞–∫—É–ø–æ–∫": email_value_goz,
            "–í–µ–±-—Å–∞–π—Ç –≥–æc. –∑–∞–∫—É–ø–æ–∫": www_value_goz,
            "–ó–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –ö–æ–º–∏—Ç–µ—Ç –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ—Ö–æ–¥–æ–≤": kgd,
            "–ó–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å –≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–µ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ": egov,
            "–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è": table_reestrs,
            "–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ:–ö–æ–º–∏—Ç–µ—Ç –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ—Ö–æ–¥–æ–≤: —É–ø–ª–∞—Ç–∞ –Ω–∞–ª–æ–≥–æ–≤": checkDate,
            "–ù–∞–ª–æ–≥–æ–≤—ã–µ –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è": tax_by_year,
        }
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª {json_file}")
        return result
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {json_file}: {str(e)}")
        return None


def process_data_parallel(json_directory, max_workers=10):
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ JSON-—Ñ–∞–π–ª–æ–≤"""
    json_files = list(Path(json_directory).glob("*.json"))
    all_data = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        future_to_file = {
            executor.submit(process_single_file, file): file for file in json_files
        }

        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –∏—Ö –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
        for future in concurrent.futures.as_completed(future_to_file):
            file = future_to_file[future]
            try:
                result = future.result()
                if result:
                    all_data.append(result)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file}: {str(e)}")

    return all_data


def flatten_nested_data(data_list):
    flattened_data = []

    for item in data_list:
        flat_item = {}

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø–æ–ª—è
        for key, value in item.items():
            if not isinstance(value, dict):
                flat_item[key] = value

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º "–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è"
        if "–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è" in item:
            for subkey, subvalue in item["–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è"].items():
                flat_item[f"–ë–ª–∞–≥–æ–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å_{subkey}"] = subvalue

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º "–ù–∞–ª–æ–≥–æ–≤—ã–µ –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è"
        if "–ù–∞–ª–æ–≥–æ–≤—ã–µ –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è" in item:
            for year, amount in item["–ù–∞–ª–æ–≥–æ–≤—ã–µ –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è"].items():
                flat_item[f"–ù–∞–ª–æ–≥–∏_{year}"] = amount

        flattened_data.append(flat_item)

    return flattened_data


def write_csv(data, output_file="company_data.csv"):
    # –°–æ–∑–¥–∞–µ–º DataFrame
    df = pd.DataFrame(data)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    df.to_csv(output_file, index=False, encoding="utf-8")
    logger.info(f"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ {output_file}")


def main():
    import time

    start_time = time.time()

    max_workers = 50  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤

    logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º {max_workers} –ø–æ—Ç–æ–∫–æ–≤...")
    data_list = process_data_parallel(json_directory, max_workers)
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(data_list)} —Ñ–∞–π–ª–æ–≤")

    logger.info("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–ª–æ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
    flat_data = flatten_nested_data(data_list)

    logger.info("–ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤ CSV...")
    write_csv(flat_data)

    elapsed_time = time.time() - start_time
    logger.info(f"–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–∫–∞—á–∏–≤–∞–Ω–Ω–∏–µ json
    num_threads = 50

    process_companies(num_threads)

    # –ü–∞—Ä—Å–∏–Ω–≥ json —Ñ–∞–π–ª–æ–≤ –∏ –∑–∞–ø–∏—Å—å–≤ csv
    main()
