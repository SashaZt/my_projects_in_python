import asyncio
import aiofiles
import hashlib
import random
import logging
from pathlib import Path
from typing import List, Optional, Dict, Any
from rnet import Impersonate, Client
import pandas as pd
from config import Config, logger, paths


class RnetDownloader:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π HTTP –∫–ª–∏–µ–Ω—Ç —Å TLS fingerprinting –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
    
    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –≠–º—É–ª—è—Ü–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±—Ä–∞—É–∑–µ—Ä–æ–≤ (Chrome, Firefox, Safari, Edge)
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–æ–∫—Å–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    - –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    - –°–ª—É—á–∞–π–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    - –†–æ—Ç–∞—Ü–∏—è User-Agent'–æ–≤
    """
    
    def __init__(self, config: Config, proxy: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞
        
        Args:
            config: –û–±—ä–µ–∫—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Config
            proxy: –ü—Ä–æ–∫—Å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "http://user:pass@host:port" –∏–ª–∏ None (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä–µ—Ç—Å—è –∏–∑ config)
        """
        self.config = config.client
        
        # –ü—Ä–æ–∫—Å–∏: –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —è–≤–Ω–æ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ, –∏–Ω–∞—á–µ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞, –∏–Ω–∞—á–µ None
        if proxy is not None:
            self.proxy = proxy
        elif self.config.proxy:
            self.proxy = self.config.proxy
        else:
            self.proxy = None
            
        self.semaphore = asyncio.Semaphore(self.config.max_workers)
        self.session_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'retry_attempts': 0
        }
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        self.output_path = Path(self.config.directories_html)
        self.output_path.mkdir(exist_ok=True)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä
        self.logger = logger
        
        # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±—Ä–∞—É–∑–µ—Ä–æ–≤ –¥–ª—è —ç–º—É–ª—è—Ü–∏–∏
        self.browsers = [
            Impersonate.Chrome134,
            Impersonate.Chrome133,
            Impersonate.Chrome132,
            Impersonate.Firefox136,
            Impersonate.Firefox135,
            Impersonate.Safari18,
            Impersonate.Safari18_2,
            Impersonate.Edge134,
            Impersonate.Edge131
        ]
    
    def _get_random_browser(self) -> Impersonate:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä –¥–ª—è —ç–º—É–ª—è—Ü–∏–∏"""
        return random.choice(self.browsers)
    
    def _get_random_user_agent(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π User-Agent –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
        return random.choice(self.config.user_agents)
    
    def _get_filename_from_url(self, url: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ URL"""
        url_hash = hashlib.md5(url.encode()).hexdigest()
        return f"{url_hash}.html"
    
    async def _make_request(self, url: str) -> Optional[str]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å HTTP –∑–∞–ø—Ä–æ—Å —Å —ç–º—É–ª—è—Ü–∏–µ–π –±—Ä–∞—É–∑–µ—Ä–∞
        
        Args:
            url: URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        for attempt in range(self.config.retry_attempts):
            try:
                # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                if attempt > 0:
                    await asyncio.sleep(self.config.retry_delay * attempt)
                else:
                    await asyncio.sleep(random.uniform(self.config.delay_min, self.config.delay_max))
                
                # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç —Å —Å–ª—É—á–∞–π–Ω—ã–º –±—Ä–∞—É–∑–µ—Ä–æ–º
                browser = self._get_random_browser()
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–ª–∏–µ–Ω—Ç–∞
                client_kwargs = {
                    'impersonate': browser,
                    'timeout': self.config.timeout
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
                if self.proxy:
                    client_kwargs['proxy'] = self.proxy
                
                async with Client(**client_kwargs) as client:
                    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
                    headers = {
                        'User-Agent': self._get_random_user_agent(),
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                        'Accept-Language': 'en-US,en;q=0.9',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                        'Sec-Fetch-Dest': 'document',
                        'Sec-Fetch-Mode': 'navigate',
                        'Sec-Fetch-Site': 'none',
                        'Sec-Fetch-User': '?1',
                        'Cache-Control': 'max-age=0'
                    }
                    
                    # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
                    response = await client.get(url, headers=headers)
                    
                    self.session_stats['total_requests'] += 1
                    
                    if response.status_code == 200:
                        content = await response.text()
                        self.session_stats['successful_requests'] += 1
                        self.logger.debug(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω: {url}")
                        return content
                    else:
                        self.logger.warning(f"‚ùå HTTP {response.status_code} –¥–ª—è {url}")
                        if response.status_code in [403, 429]:
                            # –î–ª—è 403/429 —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
                            await asyncio.sleep(random.uniform(5, 10))
                        
            except Exception as e:
                self.session_stats['retry_attempts'] += 1
                self.logger.error(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{self.config.retry_attempts} –¥–ª—è {url}: {e}")
                
                if attempt == self.config.retry_attempts - 1:
                    self.session_stats['failed_requests'] += 1
                    self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {url} –ø–æ—Å–ª–µ {self.config.retry_attempts} –ø–æ–ø—ã—Ç–æ–∫")
        
        return None
    
    async def download_url(self, url: str, filename: Optional[str] = None) -> bool:
        """
        –°–∫–∞—á–∞—Ç—å –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É
        
        Args:
            url: URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        async with self.semaphore:
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                if filename is None:
                    filename = self._get_filename_from_url(url)
                
                file_path = self.output_path / filename
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
                if file_path.exists():
                    self.logger.info(f"‚è≠Ô∏è –§–∞–π–ª {filename} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    return True
                
                # –°–∫–∞—á–∏–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                content = await self._make_request(url)
                
                if content:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
                    async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:
                        await f.write(content)
                    
                    self.logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
                    return True
                else:
                    return False
                    
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {url}: {e}")
                return False
    
    async def download_urls(self, urls: List[str], custom_filenames: Optional[Dict[str, str]] = None) -> Dict[str, bool]:
        """
        –°–∫–∞—á–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ URL'–æ–≤
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ URL'–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            custom_filenames: –°–ª–æ–≤–∞—Ä—å {url: filename} –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å {url: success_status}
        """
        self.logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É {len(urls)} URL'–æ–≤")
        self.logger.info(f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏: {self.config.max_workers} –ø–æ—Ç–æ–∫–æ–≤, –ø—Ä–æ–∫—Å–∏: {'–î–∞' if self.proxy else '–ù–µ—Ç'}")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
        tasks = []
        for url in urls:
            filename = custom_filenames.get(url) if custom_filenames else None
            task = self.download_url(url, filename)
            tasks.append((url, task))
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
        results = {}
        completed_tasks = await asyncio.gather(*[task for _, task in tasks], return_exceptions=True)
        
        for (url, _), result in zip(tasks, completed_tasks):
            if isinstance(result, Exception):
                self.logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è {url}: {result}")
                results[url] = False
            else:
                results[url] = result
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        successful = sum(1 for success in results.values() if success)
        self.logger.info(f"üìä –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {successful}/{len(urls)} —É—Å–ø–µ—à–Ω–æ")
        self.logger.info(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ—Å—Å–∏–∏: {self.session_stats}")
        
        return results
    
    async def download_from_csv(self, csv_file: str, url_column: str = 'url') -> Dict[str, bool]:
        """
        –°–∫–∞—á–∞—Ç—å URL'—ã –∏–∑ CSV —Ñ–∞–π–ª–∞
        
        Args:
            csv_file: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
            url_column: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å URL'–∞–º–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å {url: success_status}
        """
        try:
            df = pd.read_csv(csv_file)
            urls = df[url_column].tolist()
            
            self.logger.info(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(urls)} URL'–æ–≤ –∏–∑ {csv_file}")
            return await self.download_urls(urls)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ CSV —Ñ–∞–π–ª–∞: {e}")
            return {}
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–µ—Å—Å–∏–∏"""
        return self.session_stats.copy()
    
    def reset_stats(self):
        """–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–µ—Å—Å–∏–∏"""
        self.session_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'retry_attempts': 0
        }

    @classmethod
    def create_from_config(cls, config_path: Optional[str] = None, proxy_override: Optional[str] = None):
        """
        –£–¥–æ–±–Ω—ã–π –º–µ—Ç–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        
        Args:
            config_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)
            proxy_override: –ü—Ä–æ–∫—Å–∏ –¥–ª—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            
        Returns:
            –≠–∫–∑–µ–º–ø–ª—è—Ä RnetDownloader
        """
        config = Config.load()
        return cls(config, proxy_override)


# –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def download_urls_simple(urls: List[str], max_workers: int = 10, proxy: Optional[str] = None) -> Dict[str, bool]:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è URL'–æ–≤ –±–µ–∑ –ª–∏—à–Ω–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
    
    Args:
        urls: –°–ø–∏—Å–æ–∫ URL'–æ–≤
        max_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
        proxy: –ü—Ä–æ–∫—Å–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    config = Config.load()
    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º max_workers –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
    config.client.max_workers = max_workers
    
    downloader = RnetDownloader(config, proxy)
    return await downloader.download_urls(urls)


async def download_from_csv_simple(csv_file: str, max_workers: int = 10, proxy: Optional[str] = None) -> Dict[str, bool]:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑ CSV —Ñ–∞–π–ª–∞
    
    Args:
        csv_file: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
        max_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
        proxy: –ü—Ä–æ–∫—Å–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    config = Config.load()
    config.client.max_workers = max_workers
    
    downloader = RnetDownloader(config, proxy)
    return await downloader.download_from_csv(csv_file)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ RnetDownloader —Å –≤–∞—à–∏–º –∫–æ–Ω—Ñ–∏–≥–æ–º"""
    
    # –°–ø–æ—Å–æ–± 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ñ–∏–≥
    config = Config.load()
    downloader = RnetDownloader(config)
    
    # –°–ø–æ—Å–æ–± 2: –°–æ–∑–¥–∞–µ–º —á–µ—Ä–µ–∑ –∫–ª–∞—Å—Å–æ–≤—ã–π –º–µ—Ç–æ–¥
    # downloader = RnetDownloader.create_from_config()
    
    # –°–ø–æ—Å–æ–± 3: –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–∫—Å–∏
    # downloader = RnetDownloader.create_from_config(proxy_override="http://new-proxy:port")
    
    # –°–ø–∏—Å–æ–∫ URL'–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    urls = [
        "https://httpbin.org/html",
        "https://httpbin.org/json", 
        "https://httpbin.org/user-agent",
        "https://example.com"
    ]
    
    # –°–∫–∞—á–∏–≤–∞–µ–º
    results = await downloader.download_urls(urls)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    logger.info("\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    for url, success in results.items():
        status = "‚úÖ –£—Å–ø–µ—à–Ω–æ" if success else "‚ùå –û—à–∏–±–∫–∞"
        logger.info(f"{status}: {url}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    logger.info(f"\nüìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {downloader.get_stats()}")


# –ü—Ä–∏–º–µ—Ä –ø—Ä–æ—Å—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def simple_example():
    """–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞"""
    
    
    # –ò–ª–∏ –∏–∑ CSV
    results = await download_from_csv_simple("urls.csv", max_workers=5)
    
    print("–ì–æ—Ç–æ–≤–æ!", results)


if __name__ == "__main__":
    asyncio.run(main())